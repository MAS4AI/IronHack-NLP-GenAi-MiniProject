{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\IT Department\\AppData\\Local\\Temp\\ipykernel_26136\\4047422314.py:19: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAI``.\n",
      "  llm = OpenAI(temperature=0, max_tokens=2000)\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for OpenAI\n  Value error, Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass `openai_api_key` as a named parameter. [type=value_error, input_value={'temperature': 0, 'max_t...ne, 'http_client': None}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/value_error",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPyPDF2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PdfReader\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Initialize LLM\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m llm \u001b[38;5;241m=\u001b[39m OpenAI(temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, max_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2000\u001b[39m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Functions from the first app\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_insights\u001b[39m(sector, description):\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:216\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     emit_warning()\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\langchain_core\\load\\serializable.py:125\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\"\"\"\u001b[39;00m\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\pydantic\\main.py:214\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[1;34m(self, **data)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[0;32m    213\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 214\u001b[0m validated_self \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__pydantic_validator__\u001b[38;5;241m.\u001b[39mvalidate_python(data, self_instance\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[0;32m    216\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    217\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    220\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m    221\u001b[0m     )\n",
      "\u001b[1;31mValidationError\u001b[0m: 1 validation error for OpenAI\n  Value error, Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass `openai_api_key` as a named parameter. [type=value_error, input_value={'temperature': 0, 'max_t...ne, 'http_client': None}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.10/v/value_error"
     ]
    }
   ],
   "source": [
    "#!pip install -q gradio openai pypdf tiktoken langchain\n",
    "\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "\n",
    "import gradio as gr\n",
    "from langchain import OpenAI, PromptTemplate\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "# Initialize LLM\n",
    "llm = OpenAI(temperature=0, max_tokens=2000)\n",
    "\n",
    "# Functions from the first app\n",
    "def generate_insights(sector, description):\n",
    "    prompt = f\"Given a startup in the {sector} sector, with the following product description: {description}. Analyze the potential competitors and identify the challenges this product might face. Provide a brief roadmap for the startup's development and growth.\"\n",
    "    response = llm.generate([prompt])\n",
    "    return response.dict()['generations'][0][0]['text']\n",
    "\n",
    "def generate_startup_pitch(sector, description):\n",
    "    prompt = f\"Create a compelling pitch for a startup in the {sector} sector, describing their product: {description}. This pitch should highlight the unique value proposition, market potential, and why investors should consider this startup.\"\n",
    "    response = llm.generate([prompt])\n",
    "    return response.dict()['generations'][0][0]['text']\n",
    "\n",
    "def perform_domain_analysis(sector, description):\n",
    "    prompt = f\"Conduct a domain analysis for a startup in the {sector} sector with the following product description: {description}. Identify key trends, potential challenges, and opportunities in the market.\"\n",
    "    response = llm.generate([prompt])\n",
    "    return response.dict()['generations'][0][0]['text']\n",
    "\n",
    "sectors = [\n",
    "    \"Engineering\", \"Agro Chemicals\", \"Air Transport Service\", \n",
    "    \"Auto Ancillaries\", \"Automobile\", \"Banks\", \"Bearings\", \"Cables\",\n",
    "    \"Capital Goods - Electrical Equipment\", \"Capital Goods-Non Electrical Equipment\",\n",
    "    \"Castings, Forgings & Fastners\", \"Cement\", \"Cement - Products\", \"Ceramic Products\",\n",
    "    \"Chemicals\", \"Computer Education\", \"Construction\", \"Consumer Durables\",\n",
    "    \"Credit Rating Agencies\", \"Crude Oil & Natural Gas\", \"Diamond, Gems and Jewellery\",\n",
    "    \"Diversified\", \"Dry cells\", \"E-Commerce/App based Aggregator\", \"Edible Oil\",\n",
    "    \"Education\", \"Electronics\", \"Aerospace & Defence\", \"Entertainment\", \"Ferro Alloys\",\n",
    "    \"Fertilizers\", \"Finance\", \"Financial Services\", \"FMCG\", \"Gas Distribution\",\n",
    "    \"Glass & Glass Products\", \"Healthcare\", \"Hotels & Restaurants\",\n",
    "    \"Infrastructure Developers & Operators\", \"Infrastructure Investment Trusts\",\n",
    "    \"Insurance\", \"IT - Hardware\", \"IT - Software\", \"Leather\", \"Logistics\",\n",
    "    \"Marine Port & Services\", \"Media - Print/Television/Radio\", \"Mining & Mineral products\",\n",
    "    \"Miscellaneous\", \"Non Ferrous Metals\", \"Oil Drill/Allied\", \"Packaging\",\n",
    "    \"Paints/Varnish\", \"Paper\", \"Petrochemicals\", \"Pharmaceuticals\",\n",
    "    \"Plantation & Plantation Products\", \"Plastic products\", \"Plywood Boards/Laminates\",\n",
    "    \"Power Generation & Distribution\", \"Power Infrastructure\", \"Printing & Stationery\",\n",
    "    \"Quick Service Restaurant\", \"Railways\", \"Readymade Garments/ Apparells\",\n",
    "    \"Real Estate Investment Trusts\", \"Realty\", \"Refineries\", \"Refractories\", \"Retail\",\n",
    "    \"Ship Building\", \"Shipping\", \"Steel\", \"Stock/ Commodity Brokers\", \"Sugar\",\n",
    "    \"Telecom-Handsets/Mobile\", \"Telecomm Equipment & Infra Services\", \"Telecomm-Service\",\n",
    "    \"Textiles\", \"Tobacco Products\", \"Trading\", \"Tyres\", \"Other\"\n",
    "]\n",
    "\n",
    "# Functions from the second app\n",
    "def get_pdf_text(pdf_docs):\n",
    "    text = \"\"\n",
    "    for pdf in pdf_docs:\n",
    "        pdf_reader = PdfReader(pdf)\n",
    "        for page in pdf_reader.pages:\n",
    "            text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "def get_text_chunks(text):\n",
    "    text_splitter = CharacterTextSplitter(separator=\"\\n\", chunk_size=1000, chunk_overlap=200, length_function=len)\n",
    "    return text_splitter.split_text(text)\n",
    "\n",
    "def get_vectorstore(text_chunks):\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    return FAISS.from_texts(texts=text_chunks, embedding=embeddings)\n",
    "\n",
    "def get_conversation_chain(vectorstore):\n",
    "    llm = ChatOpenAI(temperature=0)\n",
    "    memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
    "    return ConversationalRetrievalChain.from_llm(llm=llm, retriever=vectorstore.as_retriever(), memory=memory)\n",
    "\n",
    "def handle_userinput(user_question, pdf_docs):\n",
    "    if not pdf_docs:\n",
    "        return \"Please upload PDFs to process.\"\n",
    "    raw_text = get_pdf_text(pdf_docs)\n",
    "    text_chunks = get_text_chunks(raw_text)\n",
    "    vectorstore = get_vectorstore(text_chunks)\n",
    "    conversation_chain = get_conversation_chain(vectorstore)\n",
    "    response = conversation_chain({'question': user_question})\n",
    "    chat_history = response['chat_history']\n",
    "    formatted_history = [f\"{'User' if i % 2 == 0 else 'Bot'}: {message.content}\" for i, message in enumerate(chat_history)]\n",
    "    return \"\\n\".join(formatted_history)\n",
    "\n",
    "def summarize_pdf(pdf_docs, custom_prompt=\"\"):\n",
    "    if not pdf_docs:\n",
    "        return \"Please upload PDFs to process.\"\n",
    "    summaries = []\n",
    "    for pdf in pdf_docs:\n",
    "        loader = PyPDFLoader(pdf)\n",
    "        docs = loader.load_and_split()\n",
    "        chain = load_summarize_chain(llm, chain_type=\"map_reduce\")\n",
    "        summary = chain.run(docs)\n",
    "        if custom_prompt:\n",
    "            prompt_template = custom_prompt + \"\"\"\n",
    "            {text}\n",
    "            SUMMARY:\"\"\"\n",
    "            PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"text\"])\n",
    "            chain = load_summarize_chain(llm, chain_type=\"map_reduce\", map_prompt=PROMPT, combine_prompt=PROMPT)\n",
    "            custom_summary = chain({\"input_documents\": docs}, return_only_outputs=True)[\"output_text\"]\n",
    "        else:\n",
    "            custom_summary = \"\"\n",
    "        summaries.append((summary, custom_summary))\n",
    "    all_summaries = []\n",
    "    for i, (base_summary, custom_summary) in enumerate(summaries):\n",
    "        final_output = f\"PDF {i+1} Summary:\\n{base_summary.strip()}\\n\"\n",
    "        if custom_summary.strip():\n",
    "            final_output += f\"\\nCustom Summary:\\n{custom_summary.strip()}\\n\"\n",
    "        all_summaries.append(final_output)\n",
    "    return \"\\n\".join(all_summaries)\n",
    "\n",
    "# Unified interface\n",
    "with gr.Blocks(theme='freddyaboulton/dracula_revamped') as interface:\n",
    "    gr.Markdown(\"## Unified Startup & PDF Processing App\")\n",
    "\n",
    "    with gr.Tab(\"Startup Tools\"):\n",
    "        with gr.Tab(\"Generate Startup Pitch\"):\n",
    "            pitch_sector_input = gr.Dropdown(label=\"Sector\", choices=sectors)\n",
    "            pitch_description_input = gr.Textbox(label=\"Description of your Product/Technology\", lines=4)\n",
    "            pitch_output = gr.Textbox(label=\"Startup Pitch\", lines=10)\n",
    "            submit_pitch_button = gr.Button(\"Generate Pitch\")\n",
    "            submit_pitch_button.click(generate_startup_pitch, inputs=[pitch_sector_input, pitch_description_input], outputs=[pitch_output])\n",
    "\n",
    "        with gr.Tab(\"Generate Insights\"):\n",
    "            insights_sector_input = gr.Dropdown(label=\"Sector\", choices=sectors)\n",
    "            insights_description_input = gr.Textbox(label=\"Description\", lines=4)\n",
    "            insights_output = gr.Textbox(label=\"Insights\", lines=10)\n",
    "            submit_insights_button = gr.Button(\"Generate Insights\")\n",
    "            submit_insights_button.click(generate_insights, inputs=[insights_sector_input, insights_description_input], outputs=[insights_output])\n",
    "\n",
    "        with gr.Tab(\"Domain Analysis\"):\n",
    "            domain_sector_input = gr.Dropdown(label=\"Sector\", choices=sectors)\n",
    "            domain_description_input = gr.Textbox(label=\"Description\", lines=4)\n",
    "            domain_output = gr.Textbox(label=\"Domain Analysis\", lines=10)\n",
    "            submit_domain_button = gr.Button(\"Perform Domain Analysis\")\n",
    "            submit_domain_button.click(perform_domain_analysis, inputs=[domain_sector_input, domain_description_input], outputs=[domain_output])\n",
    "\n",
    "    with gr.Tab(\"PDF Tools\"):\n",
    "        with gr.Tab(\"Ask the PDF\"):\n",
    "            pdf_docs_ask = gr.File(label=\"Upload your PDFs here\", file_count=\"multiple\", type=\"filepath\")\n",
    "            user_question = gr.Textbox(label=\"Ask a Question About the PDF\")\n",
    "            ask_output = gr.Textbox(label=\"Response\", interactive=False)\n",
    "            ask_pdf_btn = gr.Button(\"Ask the PDF\")\n",
    "            ask_pdf_btn.click(handle_userinput, inputs=[user_question, pdf_docs_ask], outputs=[ask_output])\n",
    "\n",
    "        with gr.Tab(\"Summarize PDF\"):\n",
    "            pdf_docs_summarize = gr.File(label=\"Upload your PDFs here\", file_count=\"multiple\", type=\"filepath\")\n",
    "            custom_prompt_input = gr.Textbox(label=\"Custom Prompt for Summarization (Optional)\")\n",
    "            summary_output = gr.Textbox(label=\"Summary Output\", interactive=False)\n",
    "            summarize_btn = gr.Button(\"Summarize PDFs\")\n",
    "            summarize_btn.click(summarize_pdf, inputs=[pdf_docs_summarize, custom_prompt_input], outputs=[summary_output])\n",
    "\n",
    "interface.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7866\n",
      "* Running on public URL: https://60424bf87cf143f229.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://60424bf87cf143f229.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!pip install -q gradio openai pypdf tiktoken langchain\n",
    "\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "\n",
    "import gradio as gr\n",
    "from langchain import OpenAI, PromptTemplate\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "# Initialize LLM\n",
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "def generate_insights(sector, description):\n",
    "    prompt = f\"Given a startup in the {sector} sector, with the following product description: {description}. Analyze the potential competitors and identify the challenges this product might face. Provide a brief roadmap for the startup's development and growth.\"\n",
    "    response = llm.generate([prompt])\n",
    "    return response.dict()['generations'][0][0]['text']\n",
    "\n",
    "def generate_startup_pitch(sector, description):\n",
    "    prompt = f\"Create a compelling pitch for a startup in the {sector} sector, describing their product: {description}. This pitch should highlight the unique value proposition, market potential, and why investors should consider this startup.\"\n",
    "    response = llm.generate([prompt])\n",
    "    return response.dict()['generations'][0][0]['text']\n",
    "\n",
    "def perform_domain_analysis(sector, description):\n",
    "    prompt = f\"Conduct a domain analysis for a startup in the {sector} sector with the following product description: {description}. Identify key trends, potential challenges, and opportunities in the market.\"\n",
    "    response = llm.generate([prompt])\n",
    "    return response.dict()['generations'][0][0]['text']\n",
    "\n",
    "sectors = [\n",
    "    \"Engineering\", \"Agro Chemicals\", \"Air Transport Service\", \n",
    "    \"Auto Ancillaries\", \"Automobile\", \"Banks\", \"Bearings\", \"Cables\",\n",
    "    \"Capital Goods - Electrical Equipment\", \"Capital Goods-Non Electrical Equipment\",\n",
    "    \"Castings, Forgings & Fastners\", \"Cement\", \"Cement - Products\", \"Ceramic Products\",\n",
    "    \"Chemicals\", \"Computer Education\", \"Construction\", \"Consumer Durables\",\n",
    "    \"Credit Rating Agencies\", \"Crude Oil & Natural Gas\", \"Diamond, Gems and Jewellery\",\n",
    "    \"Diversified\", \"Dry cells\", \"E-Commerce/App based Aggregator\", \"Edible Oil\",\n",
    "    \"Education\", \"Electronics\", \"Aerospace & Defence\", \"Entertainment\", \"Ferro Alloys\",\n",
    "    \"Fertilizers\", \"Finance\", \"Financial Services\", \"FMCG\", \"Gas Distribution\",\n",
    "    \"Glass & Glass Products\", \"Healthcare\", \"Hotels & Restaurants\",\n",
    "    \"Infrastructure Developers & Operators\", \"Infrastructure Investment Trusts\",\n",
    "    \"Insurance\", \"IT - Hardware\", \"IT - Software\", \"Leather\", \"Logistics\",\n",
    "    \"Marine Port & Services\", \"Media - Print/Television/Radio\", \"Mining & Mineral products\",\n",
    "    \"Miscellaneous\", \"Non Ferrous Metals\", \"Oil Drill/Allied\", \"Packaging\",\n",
    "    \"Paints/Varnish\", \"Paper\", \"Petrochemicals\", \"Pharmaceuticals\",\n",
    "    \"Plantation & Plantation Products\", \"Plastic products\", \"Plywood Boards/Laminates\",\n",
    "    \"Power Generation & Distribution\", \"Power Infrastructure\", \"Printing & Stationery\",\n",
    "    \"Quick Service Restaurant\", \"Railways\", \"Readymade Garments/ Apparells\",\n",
    "    \"Real Estate Investment Trusts\", \"Realty\", \"Refineries\", \"Refractories\", \"Retail\",\n",
    "    \"Ship Building\", \"Shipping\", \"Steel\", \"Stock/ Commodity Brokers\", \"Sugar\",\n",
    "    \"Telecom-Handsets/Mobile\", \"Telecomm Equipment & Infra Services\", \"Telecomm-Service\",\n",
    "    \"Textiles\", \"Tobacco Products\", \"Trading\", \"Tyres\", \"Other\"\n",
    "]\n",
    "\n",
    "def get_pdf_text(pdf_docs):\n",
    "    text = \"\"\n",
    "    for pdf in pdf_docs:\n",
    "        pdf_reader = PdfReader(pdf)\n",
    "        for page in pdf_reader.pages:\n",
    "            text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "def get_text_chunks(text):\n",
    "    text_splitter = CharacterTextSplitter(separator=\"\\n\", chunk_size=1000, chunk_overlap=200, length_function=len)\n",
    "    return text_splitter.split_text(text)\n",
    "\n",
    "def get_vectorstore(text_chunks):\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    return FAISS.from_texts(texts=text_chunks, embedding=embeddings)\n",
    "\n",
    "def get_conversation_chain(vectorstore):\n",
    "    llm = ChatOpenAI(temperature=0)\n",
    "    memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
    "    return ConversationalRetrievalChain.from_llm(llm=llm, retriever=vectorstore.as_retriever(), memory=memory)\n",
    "\n",
    "def handle_userinput(user_question, pdf_docs):\n",
    "    if not pdf_docs:\n",
    "        return \"Please upload PDFs to process.\"\n",
    "    raw_text = get_pdf_text(pdf_docs)\n",
    "    text_chunks = get_text_chunks(raw_text)\n",
    "    vectorstore = get_vectorstore(text_chunks)\n",
    "    conversation_chain = get_conversation_chain(vectorstore)\n",
    "    response = conversation_chain({'question': user_question})\n",
    "    chat_history = response['chat_history']\n",
    "    formatted_history = [f\"{'User' if i % 2 == 0 else 'Bot'}: {message.content}\" for i, message in enumerate(chat_history)]\n",
    "    return \"\\n\".join(formatted_history)\n",
    "\n",
    "def summarize_pdf(pdf_docs, custom_prompt=\"\"):\n",
    "    if not pdf_docs:\n",
    "        return \"Please upload PDFs to process.\"\n",
    "    summaries = []\n",
    "    for pdf in pdf_docs:\n",
    "        loader = PyPDFLoader(pdf)\n",
    "        docs = loader.load_and_split()\n",
    "        chain = load_summarize_chain(llm, chain_type=\"map_reduce\")\n",
    "        summary = chain.run(docs)\n",
    "        if custom_prompt:\n",
    "            prompt_template = custom_prompt + \"\"\"\n",
    "            {text}\n",
    "            SUMMARY:\"\"\"\n",
    "            PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"text\"])\n",
    "            chain = load_summarize_chain(llm, chain_type=\"map_reduce\", map_prompt=PROMPT, combine_prompt=PROMPT)\n",
    "            custom_summary = chain({\"input_documents\": docs}, return_only_outputs=True)[\"output_text\"]\n",
    "        else:\n",
    "            custom_summary = \"\"\n",
    "        summaries.append((summary, custom_summary))\n",
    "    all_summaries = []\n",
    "    for i, (base_summary, custom_summary) in enumerate(summaries):\n",
    "        final_output = f\"PDF {i+1} Summary:\\n{base_summary.strip()}\\n\"\n",
    "        if custom_summary.strip():\n",
    "            final_output += f\"\\nCustom Summary:\\n{custom_summary.strip()}\\n\"\n",
    "        all_summaries.append(final_output)\n",
    "    return \"\\n\".join(all_summaries)\n",
    "\n",
    "# Unified interface\n",
    "with gr.Blocks(theme='freddyaboulton/dracula_revamped') as interface:\n",
    "    gr.Markdown(\"## Unified Startup & PDF Processing App\")\n",
    "\n",
    "    with gr.Tab(\"Startup Tools\"):\n",
    "        with gr.Tab(\"Generate Startup Pitch\"):\n",
    "            pitch_sector_input = gr.Dropdown(label=\"Sector\", choices=sectors)\n",
    "            pitch_description_input = gr.Textbox(label=\"Description of your Product/Technology\", lines=4)\n",
    "            pitch_output = gr.Textbox(label=\"Startup Pitch\", lines=10)\n",
    "            submit_pitch_button = gr.Button(\"Generate Pitch\")\n",
    "            submit_pitch_button.click(generate_startup_pitch, inputs=[pitch_sector_input, pitch_description_input], outputs=[pitch_output])\n",
    "\n",
    "        with gr.Tab(\"Generate Insights\"):\n",
    "            insights_sector_input = gr.Dropdown(label=\"Sector\", choices=sectors)\n",
    "            insights_description_input = gr.Textbox(label=\"Description\", lines=4)\n",
    "            insights_output = gr.Textbox(label=\"Insights\", lines=10)\n",
    "            submit_insights_button = gr.Button(\"Generate Insights\")\n",
    "            submit_insights_button.click(generate_insights, inputs=[insights_sector_input, insights_description_input], outputs=[insights_output])\n",
    "\n",
    "        with gr.Tab(\"Domain Analysis\"):\n",
    "            domain_sector_input = gr.Dropdown(label=\"Sector\", choices=sectors)\n",
    "            domain_description_input = gr.Textbox(label=\"Description\", lines=4)\n",
    "            domain_output = gr.Textbox(label=\"Domain Analysis\", lines=10)\n",
    "            submit_domain_button = gr.Button(\"Perform Domain Analysis\")\n",
    "            submit_domain_button.click(perform_domain_analysis, inputs=[domain_sector_input, domain_description_input], outputs=[domain_output])\n",
    "\n",
    "    with gr.Tab(\"PDF Tools\"):\n",
    "        gr.Markdown(\"### Upload PDFs\")\n",
    "        pdf_docs = gr.File(label=\"Upload your PDFs here\", file_count=\"multiple\", type=\"filepath\")\n",
    "\n",
    "        with gr.Row():\n",
    "            # Left column: Ask the PDF\n",
    "            with gr.Column():\n",
    "                gr.Markdown(\"#### Ask the PDF\")\n",
    "                user_question = gr.Textbox(label=\"Ask a Question\")\n",
    "                ask_output = gr.Textbox(label=\"Response\", interactive=False, lines=10)\n",
    "                ask_pdf_btn = gr.Button(\"Ask the PDF\")\n",
    "                ask_pdf_btn.click(handle_userinput, inputs=[user_question, pdf_docs], outputs=[ask_output])\n",
    "            \n",
    "            # Right column: Summarize PDFs\n",
    "            with gr.Column():\n",
    "                gr.Markdown(\"#### Summarize the PDF\")\n",
    "                custom_prompt_input = gr.Textbox(label=\"Custom Prompt for Summarization (Optional)\", lines=4)\n",
    "                summary_output = gr.Textbox(label=\"Summary Output\", interactive=False, lines=10)\n",
    "                summarize_btn = gr.Button(\"Summarize PDFs\")\n",
    "                summarize_btn.click(summarize_pdf, inputs=[pdf_docs, custom_prompt_input], outputs=[summary_output])\n",
    "\n",
    "interface.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7868\n",
      "* Running on public URL: https://1413aaaaac1d3f0505.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://1413aaaaac1d3f0505.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tb/fw_49hkd2vl1gfskxm71_9xh0000gn/T/ipykernel_32417/455013346.py:29: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  return response.dict()['generations'][0][0]['text']\n",
      "/var/folders/tb/fw_49hkd2vl1gfskxm71_9xh0000gn/T/ipykernel_32417/455013346.py:24: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  return response.dict()['generations'][0][0]['text']\n",
      "/var/folders/tb/fw_49hkd2vl1gfskxm71_9xh0000gn/T/ipykernel_32417/455013346.py:34: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  return response.dict()['generations'][0][0]['text']\n"
     ]
    }
   ],
   "source": [
    "#!pip install -q gradio openai pypdf tiktoken langchain\n",
    "\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "\n",
    "import gradio as gr\n",
    "from langchain import OpenAI, PromptTemplate\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "# Initialize LLM\n",
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "def generate_insights(sector, description):\n",
    "    prompt = f\"Given a startup in the {sector} sector, with the following product description: {description}. Analyze the potential competitors and identify the challenges this product might face. Provide a brief roadmap for the startup's development and growth.\"\n",
    "    response = llm.generate([prompt])\n",
    "    return response.dict()['generations'][0][0]['text']\n",
    "\n",
    "def generate_startup_pitch(sector, description):\n",
    "    prompt = f\"Create a compelling pitch for a startup in the {sector} sector, describing their product: {description}. This pitch should highlight the unique value proposition, market potential, and why investors should consider this startup.\"\n",
    "    response = llm.generate([prompt])\n",
    "    return response.dict()['generations'][0][0]['text']\n",
    "\n",
    "def perform_domain_analysis(sector, description):\n",
    "    prompt = f\"Conduct a domain analysis for a startup in the {sector} sector with the following product description: {description}. Identify key trends, potential challenges, and opportunities in the market.\"\n",
    "    response = llm.generate([prompt])\n",
    "    return response.dict()['generations'][0][0]['text']\n",
    "\n",
    "sectors = [\n",
    "    \"Engineering\", \"Agro Chemicals\", \"Air Transport Service\", \n",
    "    \"Auto Ancillaries\", \"Automobile\", \"Banks\", \"Bearings\", \"Cables\",\n",
    "    \"Capital Goods - Electrical Equipment\", \"Capital Goods-Non Electrical Equipment\",\n",
    "    \"Castings, Forgings & Fastners\", \"Cement\", \"Cement - Products\", \"Ceramic Products\",\n",
    "    \"Chemicals\", \"Computer Education\", \"Construction\", \"Consumer Durables\",\n",
    "    \"Credit Rating Agencies\", \"Crude Oil & Natural Gas\", \"Diamond, Gems and Jewellery\",\n",
    "    \"Diversified\", \"Dry cells\", \"E-Commerce/App based Aggregator\", \"Edible Oil\",\n",
    "    \"Education\", \"Electronics\", \"Aerospace & Defence\", \"Entertainment\", \"Ferro Alloys\",\n",
    "    \"Fertilizers\", \"Finance\", \"Financial Services\", \"FMCG\", \"Gas Distribution\",\n",
    "    \"Glass & Glass Products\", \"Healthcare\", \"Hotels & Restaurants\",\n",
    "    \"Infrastructure Developers & Operators\", \"Infrastructure Investment Trusts\",\n",
    "    \"Insurance\", \"IT - Hardware\", \"IT - Software\", \"Leather\", \"Logistics\",\n",
    "    \"Marine Port & Services\", \"Media - Print/Television/Radio\", \"Mining & Mineral products\",\n",
    "    \"Miscellaneous\", \"Non Ferrous Metals\", \"Oil Drill/Allied\", \"Packaging\",\n",
    "    \"Paints/Varnish\", \"Paper\", \"Petrochemicals\", \"Pharmaceuticals\",\n",
    "    \"Plantation & Plantation Products\", \"Plastic products\", \"Plywood Boards/Laminates\",\n",
    "    \"Power Generation & Distribution\", \"Power Infrastructure\", \"Printing & Stationery\",\n",
    "    \"Quick Service Restaurant\", \"Railways\", \"Readymade Garments/ Apparells\",\n",
    "    \"Real Estate Investment Trusts\", \"Realty\", \"Refineries\", \"Refractories\", \"Retail\",\n",
    "    \"Ship Building\", \"Shipping\", \"Steel\", \"Stock/ Commodity Brokers\", \"Sugar\",\n",
    "    \"Telecom-Handsets/Mobile\", \"Telecomm Equipment & Infra Services\", \"Telecomm-Service\",\n",
    "    \"Textiles\", \"Tobacco Products\", \"Trading\", \"Tyres\", \"Other\"\n",
    "]\n",
    "\n",
    "def get_pdf_text(pdf_docs):\n",
    "    text = \"\"\n",
    "    for pdf in pdf_docs:\n",
    "        pdf_reader = PdfReader(pdf)\n",
    "        for page in pdf_reader.pages:\n",
    "            text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "def get_text_chunks(text):\n",
    "    text_splitter = CharacterTextSplitter(separator=\"\\n\", chunk_size=1000, chunk_overlap=200, length_function=len)\n",
    "    return text_splitter.split_text(text)\n",
    "\n",
    "def get_vectorstore(text_chunks):\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    return FAISS.from_texts(texts=text_chunks, embedding=embeddings)\n",
    "\n",
    "def get_conversation_chain(vectorstore):\n",
    "    llm = ChatOpenAI(temperature=0)\n",
    "    memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
    "    return ConversationalRetrievalChain.from_llm(llm=llm, retriever=vectorstore.as_retriever(), memory=memory)\n",
    "\n",
    "def handle_userinput(user_question, pdf_docs):\n",
    "    if not pdf_docs:\n",
    "        return \"Please upload PDFs to process.\"\n",
    "    raw_text = get_pdf_text(pdf_docs)\n",
    "    text_chunks = get_text_chunks(raw_text)\n",
    "    vectorstore = get_vectorstore(text_chunks)\n",
    "    conversation_chain = get_conversation_chain(vectorstore)\n",
    "    response = conversation_chain({'question': user_question})\n",
    "    chat_history = response['chat_history']\n",
    "    formatted_history = [f\"{'User' if i % 2 == 0 else 'Bot'}: {message.content}\" for i, message in enumerate(chat_history)]\n",
    "    return \"\\n\".join(formatted_history)\n",
    "\n",
    "def summarize_pdf(pdf_docs, custom_prompt=\"\"):\n",
    "    if not pdf_docs:\n",
    "        return \"Please upload PDFs to process.\"\n",
    "    summaries = []\n",
    "    for pdf in pdf_docs:\n",
    "        loader = PyPDFLoader(pdf)\n",
    "        docs = loader.load_and_split()\n",
    "        chain = load_summarize_chain(llm, chain_type=\"map_reduce\")\n",
    "        summary = chain.run(docs)\n",
    "        if custom_prompt:\n",
    "            prompt_template = custom_prompt + \"\"\"\n",
    "            {text}\n",
    "            SUMMARY:\"\"\"\n",
    "            PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"text\"])\n",
    "            chain = load_summarize_chain(llm, chain_type=\"map_reduce\", map_prompt=PROMPT, combine_prompt=PROMPT)\n",
    "            custom_summary = chain({\"input_documents\": docs}, return_only_outputs=True)[\"output_text\"]\n",
    "        else:\n",
    "            custom_summary = \"\"\n",
    "        summaries.append((summary, custom_summary))\n",
    "    all_summaries = []\n",
    "    for i, (base_summary, custom_summary) in enumerate(summaries):\n",
    "        final_output = f\"PDF {i+1} Summary:\\n{base_summary.strip()}\\n\"\n",
    "        if custom_summary.strip():\n",
    "            final_output += f\"\\nCustom Summary:\\n{custom_summary.strip()}\\n\"\n",
    "        all_summaries.append(final_output)\n",
    "    return \"\\n\".join(all_summaries)\n",
    "\n",
    "with gr.Blocks(theme='freddyaboulton/dracula_revamped') as interface:\n",
    "    gr.Markdown(\"## Unified Startup & PDF Processing App\")\n",
    "\n",
    "    with gr.Tab(\"Startup Tools\"):\n",
    "        gr.Markdown(\"### Provide Your Startup Details (Used for all Tools below)\")\n",
    "        with gr.Row():\n",
    "            selected_sector = gr.Dropdown(label=\"Sector\", choices=sectors)\n",
    "            startup_description = gr.Textbox(label=\"Description of your Product/Technology\", lines=3)\n",
    "        \n",
    "        # Each of these tabs now just has a button and output, using the same sector and description inputs.\n",
    "        with gr.Tab(\"Generate Startup Pitch\"):\n",
    "            pitch_output = gr.Textbox(label=\"Startup Pitch\", lines=10)\n",
    "            submit_pitch_button = gr.Button(\"Generate Pitch\")\n",
    "            submit_pitch_button.click(generate_startup_pitch, inputs=[selected_sector, startup_description], outputs=[pitch_output])\n",
    "\n",
    "        with gr.Tab(\"Generate Insights\"):\n",
    "            insights_output = gr.Textbox(label=\"Insights\", lines=10)\n",
    "            submit_insights_button = gr.Button(\"Generate Insights\")\n",
    "            submit_insights_button.click(generate_insights, inputs=[selected_sector, startup_description], outputs=[insights_output])\n",
    "\n",
    "        with gr.Tab(\"Domain Analysis\"):\n",
    "            domain_output = gr.Textbox(label=\"Domain Analysis\", lines=10)\n",
    "            submit_domain_button = gr.Button(\"Perform Domain Analysis\")\n",
    "            submit_domain_button.click(perform_domain_analysis, inputs=[selected_sector, startup_description], outputs=[domain_output])\n",
    "\n",
    "    with gr.Tab(\"PDF Tools\"):\n",
    "        gr.Markdown(\"### Upload PDFs\")\n",
    "        pdf_docs = gr.File(label=\"Upload your PDFs here\", file_count=\"multiple\", type=\"filepath\")\n",
    "\n",
    "        with gr.Row():\n",
    "            # Left column: Ask the PDF\n",
    "            with gr.Column():\n",
    "                gr.Markdown(\"#### Ask the PDF\")\n",
    "                user_question = gr.Textbox(label=\"Ask a Question\")\n",
    "                ask_output = gr.Textbox(label=\"Response\", interactive=False, lines=10)\n",
    "                ask_pdf_btn = gr.Button(\"Ask the PDF\")\n",
    "                ask_pdf_btn.click(handle_userinput, inputs=[user_question, pdf_docs], outputs=[ask_output])\n",
    "            \n",
    "            # Right column: Summarize PDFs\n",
    "            with gr.Column():\n",
    "                gr.Markdown(\"#### Summarize the PDF\")\n",
    "                custom_prompt_input = gr.Textbox(label=\"Custom Prompt for Summarization (Optional)\", lines=4)\n",
    "                summary_output = gr.Textbox(label=\"Summary Output\", interactive=False, lines=10)\n",
    "                summarize_btn = gr.Button(\"Summarize PDFs\")\n",
    "                summarize_btn.click(summarize_pdf, inputs=[pdf_docs, custom_prompt_input], outputs=[summary_output])\n",
    "\n",
    "interface.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7865\n",
      "* Running on public URL: https://e4225f07e23b272b04.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://e4225f07e23b272b04.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tb/fw_49hkd2vl1gfskxm71_9xh0000gn/T/ipykernel_34754/4146998840.py:38: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  return response.dict()['generations'][0][0]['text']\n",
      "/var/folders/tb/fw_49hkd2vl1gfskxm71_9xh0000gn/T/ipykernel_34754/4146998840.py:29: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  return response.dict()['generations'][0][0]['text']\n",
      "/var/folders/tb/fw_49hkd2vl1gfskxm71_9xh0000gn/T/ipykernel_34754/4146998840.py:47: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  return response.dict()['generations'][0][0]['text']\n"
     ]
    }
   ],
   "source": [
    "#!pip install -q gradio openai pypdf tiktoken langchain\n",
    "\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "\n",
    "import gradio as gr\n",
    "from langchain import OpenAI, PromptTemplate\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "# Initialize LLM\n",
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "def generate_insights(sector, description):\n",
    "    prompt = (\n",
    "        f\"You are an AI advisor assisting an aspiring entrepreneur working in the {sector} sector. \"\n",
    "        f\"They have described their product or solution as: {description}. \"\n",
    "        f\"Your task is to provide in-depth insights on potential competitors, market challenges, and key steps to refine their idea. \"\n",
    "        f\"Offer a strategic roadmap that helps them gain confidence and move forward.\"\n",
    "    )\n",
    "    response = llm.generate([prompt])\n",
    "    return response.dict()['generations'][0][0]['text']\n",
    "\n",
    "def generate_startup_pitch(sector, description):\n",
    "    prompt = (\n",
    "        f\"You are an AI mentor helping an aspiring entrepreneur craft a compelling pitch for their new idea in the {sector} sector. \"\n",
    "        f\"Their concept is: {description}. \"\n",
    "        f\"Create a pitch that clearly states the unique value proposition, showcases market potential, and encourages early supporters or investors to believe in their vision.\"\n",
    "    )\n",
    "    response = llm.generate([prompt])\n",
    "    return response.dict()['generations'][0][0]['text']\n",
    "\n",
    "def perform_domain_analysis(sector, description):\n",
    "    prompt = (\n",
    "        f\"You are an AI consultant working with an aspiring entrepreneur who has an idea in the {sector} sector. \"\n",
    "        f\"They've explained: {description}. \"\n",
    "        f\"Provide a domain analysis identifying current trends, market gaps, key opportunities, and potential risks, helping them feel more confident about the domain they are entering.\"\n",
    "    )\n",
    "    response = llm.generate([prompt])\n",
    "    return response.dict()['generations'][0][0]['text']\n",
    "\n",
    "sectors = [\n",
    "    \"Engineering\", \"Agro Chemicals\", \"Air Transport Service\", \n",
    "    \"Auto Ancillaries\", \"Automobile\", \"Banks\", \"Bearings\", \"Cables\",\n",
    "    \"Capital Goods - Electrical Equipment\", \"Capital Goods-Non Electrical Equipment\",\n",
    "    \"Castings, Forgings & Fastners\", \"Cement\", \"Cement - Products\", \"Ceramic Products\",\n",
    "    \"Chemicals\", \"Computer Education\", \"Construction\", \"Consumer Durables\",\n",
    "    \"Credit Rating Agencies\", \"Crude Oil & Natural Gas\", \"Diamond, Gems and Jewellery\",\n",
    "    \"Diversified\", \"Dry cells\", \"E-Commerce/App based Aggregator\", \"Edible Oil\",\n",
    "    \"Education\", \"Electronics\", \"Aerospace & Defence\", \"Entertainment\", \"Ferro Alloys\",\n",
    "    \"Fertilizers\", \"Finance\", \"Financial Services\", \"FMCG\", \"Gas Distribution\",\n",
    "    \"Glass & Glass Products\", \"Healthcare\", \"Hotels & Restaurants\",\n",
    "    \"Infrastructure Developers & Operators\", \"Infrastructure Investment Trusts\",\n",
    "    \"Insurance\", \"IT - Hardware\", \"IT - Software\", \"Leather\", \"Logistics\",\n",
    "    \"Marine Port & Services\", \"Media - Print/Television/Radio\", \"Mining & Mineral products\",\n",
    "    \"Miscellaneous\", \"Non Ferrous Metals\", \"Oil Drill/Allied\", \"Packaging\",\n",
    "    \"Paints/Varnish\", \"Paper\", \"Petrochemicals\", \"Pharmaceuticals\",\n",
    "    \"Plantation & Plantation Products\", \"Plastic products\", \"Plywood Boards/Laminates\",\n",
    "    \"Power Generation & Distribution\", \"Power Infrastructure\", \"Printing & Stationery\",\n",
    "    \"Quick Service Restaurant\", \"Railways\", \"Readymade Garments/ Apparells\",\n",
    "    \"Real Estate Investment Trusts\", \"Realty\", \"Refineries\", \"Refractories\", \"Retail\",\n",
    "    \"Ship Building\", \"Shipping\", \"Steel\", \"Stock/ Commodity Brokers\", \"Sugar\",\n",
    "    \"Telecom-Handsets/Mobile\", \"Telecomm Equipment & Infra Services\", \"Telecomm-Service\",\n",
    "    \"Textiles\", \"Tobacco Products\", \"Trading\", \"Tyres\", \"Other\"\n",
    "]\n",
    "\n",
    "def get_pdf_text(pdf_docs):\n",
    "    text = \"\"\n",
    "    for pdf in pdf_docs:\n",
    "        pdf_reader = PdfReader(pdf)\n",
    "        for page in pdf_reader.pages:\n",
    "            text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "def get_text_chunks(text):\n",
    "    text_splitter = CharacterTextSplitter(separator=\"\\n\", chunk_size=1000, chunk_overlap=200, length_function=len)\n",
    "    return text_splitter.split_text(text)\n",
    "\n",
    "def get_vectorstore(text_chunks):\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    return FAISS.from_texts(texts=text_chunks, embedding=embeddings)\n",
    "\n",
    "def get_conversation_chain(vectorstore):\n",
    "    llm = ChatOpenAI(temperature=0)\n",
    "    memory = ConversationBufferMemory(memory_key='chat_history', return_messages=True)\n",
    "    return ConversationalRetrievalChain.from_llm(llm=llm, retriever=vectorstore.as_retriever(), memory=memory)\n",
    "\n",
    "def handle_userinput(user_question, pdf_docs):\n",
    "    if not pdf_docs:\n",
    "        return \"Please upload PDFs to proceed.\"\n",
    "    raw_text = get_pdf_text(pdf_docs)\n",
    "    text_chunks = get_text_chunks(raw_text)\n",
    "    vectorstore = get_vectorstore(text_chunks)\n",
    "    conversation_chain = get_conversation_chain(vectorstore)\n",
    "    response = conversation_chain({'question': user_question})\n",
    "    chat_history = response['chat_history']\n",
    "    formatted_history = [f\"{'User' if i % 2 == 0 else 'AI Assistant'}: {message.content}\" for i, message in enumerate(chat_history)]\n",
    "    return \"\\n\".join(formatted_history)\n",
    "\n",
    "def summarize_pdf(pdf_docs, custom_prompt=\"\"):\n",
    "    if not pdf_docs:\n",
    "        return \"Please upload PDFs to proceed.\"\n",
    "    summaries = []\n",
    "    for pdf in pdf_docs:\n",
    "        loader = PyPDFLoader(pdf)\n",
    "        docs = loader.load_and_split()\n",
    "        chain = load_summarize_chain(llm, chain_type=\"map_reduce\")\n",
    "        summary = chain.run(docs)\n",
    "        if custom_prompt:\n",
    "            prompt_template = custom_prompt + \"\"\"\n",
    "            {text}\n",
    "            SUMMARY:\"\"\"\n",
    "            PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"text\"])\n",
    "            chain = load_summarize_chain(llm, chain_type=\"map_reduce\", map_prompt=PROMPT, combine_prompt=PROMPT)\n",
    "            custom_summary = chain({\"input_documents\": docs}, return_only_outputs=True)[\"output_text\"]\n",
    "        else:\n",
    "            custom_summary = \"\"\n",
    "        summaries.append((summary, custom_summary))\n",
    "    all_summaries = []\n",
    "    for i, (base_summary, custom_summary) in enumerate(summaries):\n",
    "        final_output = f\"PDF {i+1} Summary:\\n{base_summary.strip()}\\n\"\n",
    "        if custom_summary.strip():\n",
    "            final_output += f\"\\nCustom Summary:\\n{custom_summary.strip()}\\n\"\n",
    "        all_summaries.append(final_output)\n",
    "    return \"\\n\".join(all_summaries)\n",
    "\n",
    "with gr.Blocks(theme='freddyaboulton/dracula_revamped') as interface:\n",
    "    gr.Markdown(\"## Idea Empowerment & Investment Guidance Platform\")\n",
    "    gr.Markdown(\"\"\"\n",
    "    Welcome to your all-in-one assistant for nurturing new ideas and supporting confident decision-making.\n",
    "    This platform offers two main areas:\n",
    "    - **Founder Confidence Tools**: For aspiring entrepreneurs looking to refine their ideas, understand their market, and pitch with clarity.\n",
    "    - **Investor Decision Support**: For investors who want a diligent, AI-driven partner to summarize and explore documents, reducing uncertainty in the investment decision process.\n",
    "    \"\"\")\n",
    "\n",
    "    with gr.Tab(\"Founder Confidence Tools\"):\n",
    "        gr.Markdown(\"### Step 1: Define Your Idea\")\n",
    "        gr.Markdown(\"Provide details about your startup concept. This information will be used across all tools below.\")\n",
    "        with gr.Row():\n",
    "            selected_sector = gr.Dropdown(label=\"Select Your Startup's Sector\", choices=sectors)\n",
    "            startup_description = gr.Textbox(label=\"Describe Your Idea or Product\", placeholder=\"Explain what your startup does and what problem it solves.\", lines=3)\n",
    "        \n",
    "        gr.Markdown(\"### Explore Tools to Gain Confidence\")\n",
    "        with gr.Tab(\"Craft Your Pitch\"):\n",
    "            gr.Markdown(\"Generate a compelling, investor-ready pitch to communicate your idea's value and potential.\")\n",
    "            pitch_output = gr.Textbox(label=\"Your Pitch\", lines=10)\n",
    "            submit_pitch_button = gr.Button(\"Generate Pitch\")\n",
    "            submit_pitch_button.click(generate_startup_pitch, inputs=[selected_sector, startup_description], outputs=[pitch_output])\n",
    "\n",
    "        with gr.Tab(\"Gain Market Insights\"):\n",
    "            gr.Markdown(\"Receive insights on competitors, challenges, and strategic steps, helping you build confidence in your venture.\")\n",
    "            insights_output = gr.Textbox(label=\"Market Insights\", lines=10)\n",
    "            submit_insights_button = gr.Button(\"Get Insights\")\n",
    "            submit_insights_button.click(generate_insights, inputs=[selected_sector, startup_description], outputs=[insights_output])\n",
    "\n",
    "        with gr.Tab(\"Domain Analysis\"):\n",
    "            gr.Markdown(\"Understand the current landscape and opportunities in your chosen domain.\")\n",
    "            domain_output = gr.Textbox(label=\"Domain Analysis\", lines=10)\n",
    "            submit_domain_button = gr.Button(\"Perform Domain Analysis\")\n",
    "            submit_domain_button.click(perform_domain_analysis, inputs=[selected_sector, startup_description], outputs=[domain_output])\n",
    "\n",
    "    \n",
    "\n",
    "    with gr.Tab(\"Investor Decision Support\"):\n",
    "        gr.Markdown(\"### Upload Relevant Documents\")\n",
    "        gr.Markdown(\"Whether it's a startup's pitch deck, business plan, or financial data, upload PDFs here to get summaries and clarifications.\")\n",
    "\n",
    "        with gr.Tab(\"Ask the PDF\"):\n",
    "            gr.Markdown(\"#### Interrogate the Documents\")\n",
    "            gr.Markdown(\"Ask specific questions about the uploaded files to clarify details and reduce uncertainty.\")\n",
    "            pdf_docs_ask = gr.File(label=\"Upload your PDFs here\", file_count=\"multiple\", type=\"filepath\")\n",
    "            user_question = gr.Textbox(label=\"Ask a Question\")\n",
    "            ask_output = gr.Textbox(label=\"AI Assistant's Response\", interactive=False, lines=10)\n",
    "            ask_pdf_btn = gr.Button(\"Ask\")\n",
    "            ask_pdf_btn.click(handle_userinput, inputs=[user_question, pdf_docs_ask], outputs=[ask_output])\n",
    "\n",
    "        with gr.Tab(\"Summarize PDF\"):\n",
    "            gr.Markdown(\"#### Get Condensed Summaries\")\n",
    "            gr.Markdown(\"Generate a summary of the entire document set, or provide a custom prompt for a specialized summary.\")\n",
    "              pdf_docs_summarize = gr.File(label=\"Upload your PDFs here\", file_count=\"multiple\", type=\"filepath\")\n",
    "            custom_prompt_input = gr.Textbox(label=\"Optional Custom Prompt\", placeholder=\"E.g., 'Focus on financial metrics and growth projections.'\", lines=4)\n",
    "            summary_output = gr.Textbox(label=\"Summary Output\", interactive=False, lines=10)\n",
    "            summarize_btn = gr.Button(\"Summarize\")\n",
    "            summarize_btn.click(summarize_pdf, inputs=[pdf_docs_summarize, custom_prompt_input], outputs=[summary_output])\n",
    "\n",
    "interface.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
